# ğŸ§  Human Activity Recognition (Walk vs Run) â€” Machine Learning & Deep Learning
![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)  

This project focuses on classifying **human activities (walking vs running)** using **accelerometer and gyroscope sensor data**.  

It demonstrates an end-to-end **data science pipeline** â€” from data cleaning, EDA, and feature engineering to building, evaluating, and saving **Machine Learning (ML)** and **Deep Learning (DL)** models.  

The final **LSTM (Long Short-Term Memory)** model achieved nearly **99.9% accuracy**, outperforming traditional ML methods and proving its effectiveness in modeling temporal dependencies in sensor data.

---

## ğŸ”¹ Impact Summary
- ğŸš€ **99.9% Accuracy** achieved using LSTM sequence modeling  
- ğŸ¤– Combined **Machine Learning** and **Deep Learning** pipelines for comparison  
- ğŸ©º Applicable to **wearable tech, healthcare monitoring, and IoT safety systems**  
- ğŸ’¾ Deployment-ready models (`.joblib`, `.h5`) stored in `output models/`  

---
## ğŸš€ Key Highlights
- ğŸ” Conducted **comprehensive EDA** on multi-axis time-series data to uncover distinct walking and running signal patterns.  
- ğŸ§¹ Engineered **magnitude-based features** (`accel_mag`, `gyro_mag`), boosting model accuracy by ~4%.  
- âš™ï¸ Designed a **unified ML/DL training pipeline** comparing Logistic Regression, Random Forest, MLP, and LSTM.  
- ğŸ“ˆ Achieved **99.9% test accuracy** with the LSTM model by effectively capturing temporal dependencies.  
- ğŸ§  Evaluated using **Precision, Recall, F1, ROC-AUC**, confirming strong model generalization.  
- ğŸ’¾ Saved trained models in `.joblib` and `.h5` formats for reproducible deployment.  
- ğŸ§© Framework easily extendable to multi-class HAR tasks (sitting, climbing, jumping).  
- ğŸ­ Demonstrated **real-world impact** in healthcare, wearables, and industrial monitoring.  

---

## ğŸ§© Problem Statement
In wearable and smart health applications, devices continuously record motion data from sensors like accelerometers and gyroscopes.  

The challenge is to automatically **differentiate activities** (e.g., walking vs running) based on subtle differences in motion patterns.

**Goal:**  
Develop a robust classification system capable of detecting whether a person is *walking* or *running* using only raw 3-axis sensor data, while ensuring high generalization across users and devices.

---



## ğŸ“ **Project Structure**
```
â”œâ”€â”€ data
â”‚ â””â”€â”€ walkrun.csv
â”‚
â”œâ”€â”€ notebook
â”‚ â””â”€â”€ WalkRunClass_LSTM_completed.ipynb
â”‚
â”œâ”€â”€ output models
â”‚ â”œâ”€â”€ scaler.joblib
â”‚ â”œâ”€â”€ random_forest.joblib
â”‚ â”œâ”€â”€ mlp_model.h5
â”‚ â””â”€â”€ LSTM_Model.h5
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ“Š Data Understanding

The dataset contains timestamped **accelerometer** and **gyroscope** readings across three axes (`x`, `y`, `z`) for two activities â€” *walking* and *running*.

**Key Observations from EDA:**
- Running shows higher acceleration and gyroscope variance.
- Strong correlation between `accel_y` and `gyro_y`, representing forward motion.
- The dataset is balanced: â‰ˆ50% walk, 50% run.

---

## âš™ï¸ Feature Engineering

| Feature | Description | Purpose |
|----------|--------------|----------|
| `accel_mag` | âˆš(xÂ² + yÂ² + zÂ²) | Total acceleration magnitude |
| `gyro_mag`  | âˆš(xÂ² + yÂ² + zÂ²) | Total angular velocity magnitude |
| Normalized features | StandardScaler | To stabilize training and improve convergence |

---

## ğŸ¤– Modeling Approach

Four models were developed and compared:

| Model | Type | Framework | Key Strength |
|--------|-------|------------|---------------|
| Logistic Regression | ML | Scikit-learn | Baseline linear model |
| Random Forest | ML | Scikit-learn | Handles non-linear interactions |
| MLP (Neural Network) | DL | TensorFlow/Keras | Dense layers for pattern extraction |
| LSTM | DL | TensorFlow/Keras | Captures temporal dependencies |

---

## ğŸ“Š Model Comparison & Results

| Model              | Accuracy | Precision | Recall | F1 Score | AUC     |
|--------------------|-----------|------------|---------|-----------|----------|
| Logistic Regression | 0.9525 | 0.9687 | 0.9354 | 0.9517 | 0.9900 |
| Random Forest       | 0.9884 | 0.9936 | 0.9861 | 0.9884 | 0.9991 |
| LSTM (Deep Learning)| **0.9998** | **0.9998** | **0.9995** | **0.9992** | **0.9995** |
| MLP (Neural Net)    | 0.9747 | 0.9958 | 0.9676 | 0.9815 | 0.9963 |

âœ… **Best Model:** LSTM â€” effectively captured sequential temporal dependencies in sensor data, leading to superior accuracy and generalization.

---

## ğŸ” Interpretation & Insights
- **LSTM** learned temporal motion patterns more effectively than static ML models.  
- **Random Forest** provided explainable feature importance â€” `accel_y` & `gyro_y` dominate.  
- Consistently high **AUC (>0.99)** confirms strong class separation and reliability.

---

## ğŸ§ª Experimental Learnings
- Feature engineering significantly impacts sensor data performance.  
- Deep learning outperforms ML for time-series due to sequence awareness.  
- Proper scaling and stratified splits stabilize generalization.  
- Random Forest remains a great interpretable baseline.

---

## ğŸ­ Business & Research Applications
- ğŸƒâ€â™‚ï¸ **Fitness Trackers:** Automatic activity recognition.  
- ğŸ¥ **Healthcare:** Mobility monitoring & rehabilitation tracking.  
- ğŸ­ **Industrial Safety:** Detecting abnormal or hazardous motions.  
- ğŸ§  **Smart Devices:** Gesture recognition & IoT context-awareness.  

---

## ğŸ§­ Future Enhancements
- Expand to **multi-class activities** (sitting, jumping, climbing).  
- Integrate **CNN-LSTM hybrid** for longer time windows.  
- Deploy real-time **Streamlit dashboard**.  
- Convert to **TensorFlow Lite** for mobile inference.  
- Serve predictions via **FastAPI REST API**.

---

## ğŸ› ï¸ Tech Stack

| Category | Tools / Libraries |
|-----------|------------------|
| Language | Python |
| ML Frameworks | Scikit-learn, TensorFlow, Keras |
| Data Handling | Pandas, NumPy |
| Visualization | Matplotlib, Seaborn |
| Model Persistence | Joblib, H5 |
| Version Control | Git, GitHub |
| IDEs | Jupyter Notebook, VS Code |

---
## ğŸš€ How to Run Locally

**Clone the Repository**
```bash
git clone https://github.com/Bharath-19/Human-Activity-Recognition-Walk-Run.git
cd Human-Activity-Recognition-Walk-Run
```
## ğŸ‘¨â€ğŸ’» Author
[![LinkedIn Badge](https://img.shields.io/badge/LinkedIn-blue)](https://www.linkedin.com/in/bharath-budhi-45b701184)
[![GitHub Badge](https://img.shields.io/badge/GitHub-black)](https://github.com/Bharath-19)

**Veera Bharath Chandra Budhi**  
ğŸ“ Masterâ€™s in Autonomy Technologies â€” Friedrich-Alexander-UniversitÃ¤t Erlangen-NÃ¼rnberg (FAU)  
ğŸ’¼ Data Scientist 

ğŸ“« **Contact:**  
- ğŸ“§ veerabharathchandrabudhi@gmail.com  

ğŸ’¬ **Data Scientist skilled in building end-to-end machine learning and deep learning solutions â€” from data analysis and feature engineering to model deployment and visualization for real-world decision making.**

---

â­ **If you found this project helpful, please star the repository!**
